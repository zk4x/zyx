[package]
name = "zyx"
version = "0.15.0"
edition = "2021"
authors = ["zk4x"]
description = "Zyx machine learning library"
documentation = "https://docs.rs/zyx"
readme = "README.md"
homepage = "https://github.com/zk4x/zyx"
repository = "https://github.com/zk4x/zyx"
license = "MIT OR Apache-2.0"
keywords = ["tensor", "deep-learning", "neural-network", "autodiff"]
categories = ["computer-vision", "science"]

[badges]
maintenance = { status = "experimental" }

[dependencies]
# libloading is used to access cuda, opencl and hsa runtimes
libloading = { version = "0.8.5", default-features = false } # ISC
# serde is used to read backend config
serde = { version = "1.0.209", default-features = false, features = [
    "std",
    "derive",
] } # MIT or Apache 2.0
# JSON is used to read backend config
serde_json = { version = "1.0.128", default-features = false, features = [
    "std",
] } # MIT or Apache 2.0
# xdg is used to read backend config
xdg = { version = "2.5.2", default-features = false } # MIT or Apache 2.0
# For nice colorful debug logging
inline_colorization = { version = "0.1.6", default-features = false } # MIT
# Support for f16 and bf16 dtypes
float8 = { version = "0.1.1" } # MIT or Apache 2.0
# Support for f16 and bf16 dtypes
half = { version = "2.4.1" } # MIT or Apache 2.0

# Optional dependencies
# Support for random number generation
rand = { version = "0.8.5", default-features = false, features = [
    "small_rng",
], optional = true } # MIT or Apache 2.0
# for caching of searched kernels
bitcode = { version = "0.6.3", default-features = false, features = [
    "std",
    "derive",
], optional = true } # MIT or Apache 2.0
# Support for cf32 and cf64 dtypes
num-complex = { version = "0.4.6", default-features = false, optional = true } # MIT or Apache 2.0

# Lot of dependencies from wgpu, probably just don't use that
wgpu = { version = "22.1.0", default-features = false, features = [
    "wgsl",
], optional = true }
# Futures for wgpu axync mess. Some functions are async, while others using polling and it's a mess that deadlocks
futures = { version = "0.3", default-features = false, features = [
    "executor",
], optional = true }

# gguf models
gguf = { version = "0.1.2", default-features = false, optional = true }

# Pyo3 is used only for python bindings
pyo3 = { version = "0.22.2", optional = true } # MIT or Apache 2.0

[lib]
crate-type = ["lib", "cdylib"]

[features]
default = [
    "rand",
    #"disk_cache",
    #"wgsl",
    #"complex",
    "gguf",
    #"py",
]

# Enables random number generation for randn, uniform ...
rand = ["dep:rand"]

disk_cache = ["dep:bitcode"]

# Enables complex f32 and complex f64 dtypes
complex = ["dep:num-complex"]

# Enables us to create python bindings with pyo3, annotates structs with pyclass
py = ["dep:pyo3", "rand", "complex"]

# Enables wgsl backend
wgsl = ["dep:wgpu", "dep:futures"]

# Enables loading of gguf models
gguf = ["dep:gguf"]

# Optimize for linking time, 'cause linker is so slow...
[profile.dev] # Modify profile settings via config.
opt-level = 0 # Optimization level.
debug = false # Include debug info.
#split-debuginfo = '...'  # Debug info splitting behavior.
strip = false           # Removes symbols or debuginfo.
debug-assertions = true # Enables debug assertions.
overflow-checks = true  # Enables runtime integer overflow checks.
lto = false             # Sets link-time optimization.
panic = 'unwind'        # The panic strategy.
incremental = true      # Incremental compilation.
codegen-units = 16      # Number of code generation units.
#rpath = false            # Sets the rpath linking option.

# This is just a runtime, no need for o3 vectorization and crazy function inlining
[profile.release]
opt-level = "z"
strip = true
debug-assertions = false
overflow-checks = true
lto = true
panic = "abort"
incremental = false
codegen-units = 1
debug = 0

# Just for the fuzzy tester
#[profile.test]
#opt-level = 3
#strip = true
#debug-assertions = false
#overflow-checks = true
#lto = true
#panic = "abort"
#incremental = false
#codegen-units = 1
#debug = 0
