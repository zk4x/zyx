<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="zyx-book"><a class="header" href="#zyx-book">Zyx book</a></h1>
<p>This book is an introductory to machine learning with zyx library.</p>
<p>It is meant to serve as a tutorial and provide examples of working with zyx. For documentation, please see:</p>
<ul>
<li><a href="https://docs.rs/zyx-core/latest/zyx-core">core</a></li>
<li><a href="https://docs.rs/zyx-optim/latest/zyx-optim">optimizers</a></li>
<li><a href="https://docs.rs/zyx-nn/latest/zyx-nn">neural network modules</a></li>
</ul>
<p>For documentation on zyx backends:</p>
<ul>
<li><a href="https://docs.rs/zyx-cpu/latest/zyx-cpu">cpu</a></li>
<li><a href="https://docs.rs/zyx-opencl/latest/zyx-opencl">opencl</a></li>
<li><a href="https://docs.rs/zyx-cpu/latest/zyx-torch">torch</a></li>
</ul>
<p>If you are already familiar with machine learning and want the quickest possible tutorial, please see <a href="https://www.github.com/zk4x/zyx">README</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-create-zyx"><a class="header" href="#why-create-zyx">Why create zyx?</a></h1>
<p>Zyx was created as a learning exercise to understand machine learning from low level, close to the metal perspective.
As the time went on, I saw the lack of good ML libraries in Rust ecosystem which meant that if zyx got completed,
other people could use it too.</p>
<p>When researching architecture of other ML libraries, in particular the most popular ones - pytorch and tensorflow,
I found that their creators made certain compromises in order to simplify the development and reach the widest
possible audience.</p>
<p>These days we have a pretty good perspective on what a good ML library should look like. It should run on all hardware
with solid performance, it should not take too much disk space or memory and it should be easy to use.
Crucially it does not need to support many operations, just a few unary, binary, movement and reduce operations
are plenty, as shown by tinygrad.</p>
<p>In zyx, core operations are rarely added, but adding backends is very simple. Zyx automatically optimizes
for backpropagation and uses as little memory as possible during both training and inference.</p>
<p>And as for the ease of use? I want you to be the judge of that.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="first-tensors"><a class="header" href="#first-tensors">First tensors</a></h1>
<p>In this chapter we go over tensor initialization and running your first operations.</p>
<h2 id="choosing-your-backend"><a class="header" href="#choosing-your-backend">Choosing your backend</a></h2>
<p>Zyx automatically chooses the best backend for you.</p>
<h2 id="tensor-1"><a class="header" href="#tensor-1">Tensor #1</a></h2>
<p>Now we can create your first tensor with zyx.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let x = dev.tensor([[[3, 2]], [[3, 4]]]);
<span class="boring">}</span></code></pre></pre>
<p>Tensor is multidimensional array. We can ask how many dimensions it has.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>assert_eq!(x.rank(), 3);
<span class="boring">}</span></code></pre></pre>
<p>And also what those dimensions are.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>assert_eq!(x.shape(), [2, 1, 2]);
<span class="boring">}</span></code></pre></pre>
<p>Tensors can only hold data of a single type. In this case, it is i32.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>assert_eq!(x.dtype(), DType::I32);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-operations"><a class="header" href="#tensor-operations">Tensor Operations</a></h1>
<p>Zyx supports most important operations used in other ML libraries.</p>
<p>Examples. For full list, please check tensor's <a href="https://docs.rs/zyx-core/latest/zyx-core/tensor/struct.Tensor.html">documentation</a>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let x = Tensor::randn([1024, 1024], DType::F32);
let y = Tensor::randn([1024, 1024], DType::F32);

let z = x.exp();
let z = x.relu();
let z = x.sin();
let z = x.tanh();

let z = &amp;x + &amp;y;
let z = &amp;x - &amp;y;
let z = &amp;x * &amp;y;
let z = &amp;x / &amp;y;
let z = x.pow(&amp;y);
let z = x.cmplt(&amp;y);
let z = x.dot(&amp;y);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="automatic-differentiation-in-zyx"><a class="header" href="#automatic-differentiation-in-zyx">Automatic Differentiation in Zyx</a></h1>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<p>Zyx implements automatic differentiation through an explicit gradient tape system. Any differentiable mathematical operation can be automatically tracked and differentiated, including functions like ReLU that have points of non-differentiability in traditional calculus.</p>
<h2 id="example-workflow"><a class="header" href="#example-workflow">Example Workflow</a></h2>
<h3 id="forward-pass-with-gradient-tape"><a class="header" href="#forward-pass-with-gradient-tape">Forward Pass with Gradient Tape</a></h3>
<p>Create a gradient tape and perform tensor operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use zyx::{Tensor, GradientTape, DType};

let tape = GradientTape::new();
let x = Tensor::randn([1024, 1024], DType::F32);
let y = Tensor::from([2, 3, 1]);
let z = (x + y.pad([(1000, 21)], 8)) * x;
<span class="boring">}</span></code></pre></pre>
<h3 id="backward-pass-via-gradient-tape"><a class="header" href="#backward-pass-via-gradient-tape">Backward Pass via Gradient Tape</a></h3>
<p>Compute gradients using the tape:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let grads = tape.gradient(&amp;z, &amp;[&amp;x, &amp;y]);
<span class="boring">}</span></code></pre></pre>
<h3 id="gradient-handling"><a class="header" href="#gradient-handling">Gradient Handling</a></h3>
<p>The <code>gradient</code> method returns <code>Vec&lt;Option&lt;Tensor&gt;&gt;</code> where <code>None</code> indicates no computational path:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tape = GradientTape::new();
let x = Tensor::randn([2, 3], DType::F32);
let y = Tensor::randn([2, 3], DType::F32);
let z = y.exp();
let grads = tape.gradient(&amp;z, &amp;[&amp;x]);
assert_eq!(grads, vec![None]);  // No gradient for x since z doesn't depend on it
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-advantages"><a class="header" href="#performance-advantages">Performance Advantages</a></h2>
<h3 id="tape-based-computation"><a class="header" href="#tape-based-computation">Tape-Based Computation</a></h3>
<p>Zyx's autograd system:</p>
<ul>
<li>Uses an explicit <code>GradientTape</code> to record operations</li>
<li>Only computes gradients when explicitly requested</li>
<li>Optimizes memory usage through lazy evaluation</li>
<li>Supports higher-order derivatives with persistent gradient tapes</li>
</ul>
<p>This architecture enables efficient differentiation while maintaining flexibility for complex computational graphs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="optimizers"><a class="header" href="#optimizers">Optimizers</a></h1>
<pre><code class="language-shell">cargo add zyx-optim
</code></pre>
<p>Optimizers take gradients calculated as your loss w.r.t. your parameters and update those parameters
so that the next time you run your model with the same inputs, the loss will be lower.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut optim = zyx_optim::SGD { ..Default::default() };
let grads = loss.backward();
optim.update(&amp;mut model, grads);
<span class="boring">}</span></code></pre></pre>
<p>Zyx has multiple optimizers. All are accessible from crate <a href="https://docs.rs/zyx-optim/latest/zyx-optim/index.html">zyx-optim</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-modules"><a class="header" href="#creating-modules">Creating Modules</a></h1>
<pre><code class="language-shell">cargo add zyx-nn
</code></pre>
<p>Zyx only has statefull modules. That is all modules must store one or more tensors. One of the simplest modules
is <a href="https://docs.rs/zyx-nn/latest/zyx-nn/struct.Linear.html">linear layer</a>.</p>
<p>In order to initialize modules, you need a device. Modules have traits implemented for all backends to allow for more ergonomic API:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use zyx_nn::Linear;
let l0 = Linear::new(1024, 128, DType::F32);
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-modules"><a class="header" href="#custom-modules">Custom Modules</a></h2>
<p>Custom modules are easy to create, you only need to import Backend trait from core.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct MyModule {
    l0: Linear,
    l1: Linear,
}
<span class="boring">}</span></code></pre></pre>
<p>For modules to be useful, they need forward function.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl MyModule {
    fn forward(&amp;self, x: impl Into&lt;Tensor&gt;) -&gt; Tensor {
        let x = self.l0.forward(x).relu();
        self.l1.forward(x).sigmoid()
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Since relu is stateless, it is not a module, it is just a function on tensor.</p>
<p>Modules can be initialized with any device.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let dev = zyx_cpu::device()?;

let my_module = MyModule {
    l0: Linear::new(1024, 512, DType::F32),
    l1: Linear::new(512, 128, DType::F32),
};
<span class="boring">}</span></code></pre></pre>
<p>Also you need to implement IntoIterator&lt;Item = &amp;Tensor&gt; to be able to easily save and IntoIterator&lt;Item = &amp;mut Tensor&gt;
to backpropagate over parameters of the module and to load these parameters into the model.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;'a&gt; IntoIterator for &amp;'a MyModule {
    type Item = &amp;'a Tensor;
    type IntoIter = impl IntoIterator&lt;Item = Self::Item&gt;;
    fn into_iter(self) -&gt; Self::IntoIter {
        self.l0.into_iter().chain(self.l1)
    }
}

impl&lt;'a&gt; IntoIterator for &amp;'a mut MyModule {
    type Item = &amp;'a mut Tensor;
    type IntoIter = impl IntoIterator&lt;Item = Self::Item&gt;;
    fn into_iter(self) -&gt; Self::IntoIter {
        self.l0.into_iter().chain(self.l1)
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Both implementations of IntoIterator could be done using procedural macro Module.
So you can choose this simpler method if you prefer.</p>
<pre><code class="language-shell">cargo add zyx_derive
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Module)]
struct MyModule {
    l0: Linear,
    l1: Linear,
}
<span class="boring">}</span></code></pre></pre>
<p>Forward function is used for inference.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let input = Tensor::randn([8, 1024], DType::F32);

let out = my_module.forward(&amp;input);
<span class="boring">}</span></code></pre></pre>
<p>Backpropagation is provided automatically.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let input = Tensor::randn([8, 1024], DType::F32);
let label = Tensor::randn([8, 128], DType::F32);

let epochs = 100;
for _ in 0..epochs {
    let out = my_module.forward(&amp;input);
    let loss = (out - label).pow(2);
    loss.backward(&amp;my_module);
}
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disk-io"><a class="header" href="#disk-io">Disk IO</a></h1>
<p>Zyx does not have special trait for modules. Instead all modules implement IntoIterator&lt;&amp;Tensor&gt; and IntoIterator&lt;&amp;mut Tensor&gt;.</p>
<p>Anything that implements the first trait can be saved.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let model = Linear::new(1024, 128, DType::F32);

model.save("model.safetensors")?;
<span class="boring">}</span></code></pre></pre>
<p>Zyx uses safetensors format for saving tensors.</p>
<p>Loading is similar.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut model = Linear::load("model.safetensors")?;
<span class="boring">}</span></code></pre></pre>
<p>If you don't know the structure of tensors saved on disks, you can load them like this.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tensors = Tensor::load("my_tensors.safetensors")?;
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="library-vs-framework-the-zyx-philosophy"><a class="header" href="#library-vs-framework-the-zyx-philosophy">Library vs. Framework: The Zyx Philosophy</a></h1>
<h2 id="core-philosophy"><a class="header" href="#core-philosophy">Core Philosophy</a></h2>
<p>Zyx is designed as a <strong>library</strong>, not a framework. This distinction is critical for developers who value flexibility and control over their machine learning workflows. While frameworks impose rigid structures and design patterns, libraries like Zyx adapt to your needs, enabling seamless integration into any project architecture.</p>
<p>This philosophy manifests in several key ways:</p>
<ul>
<li><strong>No scaffolding requirements</strong>: Zyx doesn't force you to follow specific project templates or directory structures</li>
<li><strong>No global state</strong>: Unlike frameworks that maintain persistent runtime state, Zyx operations are localized to individual tensors</li>
<li><strong>No enforced abstractions</strong>: You're free to build your own abstractions without fighting framework conventions</li>
</ul>
<h2 id="technical-advantages"><a class="header" href="#technical-advantages">Technical Advantages</a></h2>
<h3 id="1-zero-design-enforcement"><a class="header" href="#1-zero-design-enforcement">1. Zero Design Enforcement</a></h3>
<p>Zyx avoids dictating how you structure your code. This means:</p>
<ul>
<li><strong>No mandatory base classes</strong>: You're not required to implement predefined interfaces.</li>
<li><strong>No opinionated training loops</strong>: Unlike many ML frameworks that provide a single <code>fit()</code> or <code>train()</code> method, Zyx allows you to build custom training loops tailored to your application's requirements.</li>
<li><strong>No static graph requirements</strong>: Zyx's tape-based autograd system (see <a href="autograd.html">autograd documentation</a>) records gradients only when needed, without requiring upfront graph definitions.</li>
</ul>
<h3 id="2-minimal-compilation-footprint"><a class="header" href="#2-minimal-compilation-footprint">2. Minimal Compilation Footprint</a></h3>
<p>Zyx is engineered to be <strong>tiny when compiled</strong>, making it ideal for users who want to keep their disk free. It's just a few MB.</p>
<p>This lightweight nature stems from:</p>
<ul>
<li><strong>No code generation</strong>: Zyx avoids macros that expand into large codebases</li>
<li><strong>No feature flags bloat</strong>: Most functionality and hardware works without enabling any features</li>
<li><strong>No unnecessary abstractions</strong>: Extensive ops support, without traits or generics</li>
</ul>
<p>The benefits are tangible:</p>
<ul>
<li><strong>Embedded systems</strong>: Deploy ML capabilities in resource-constrained environments</li>
<li><strong>Edge computing</strong>: Run inference on devices with limited storage capacity</li>
<li><strong>Fast iteration</strong>: Quick recompilation during development cycles</li>
<li><strong>No generic/lifetime headaches</strong>: Spend time writing your code, not refactoring to fit into the framework</li>
</ul>
<h3 id="3-dependency-management"><a class="header" href="#3-dependency-management">3. Dependency Management</a></h3>
<p>Zyx maintains a <strong>minimal dependency profile</strong>:</p>
<ul>
<li><strong>Core dependencies</strong>: Only essential libraries like <code>nanoserde</code> for config parsing and <code>libloading</code> for dynamic backend loading.</li>
<li><strong>Optional features</strong>: Big dependencies (e.g., WGPU backend) are available as features that can be enabled when needed.</li>
<li><strong>No dependency bloat</strong>: Zyx avoids unnecessary dependencies that could increase binary size or complexity.</li>
</ul>
<p>This approach offers several advantages:</p>
<ul>
<li><strong>Reduced security surface</strong>: Fewer dependencies mean fewer potential vulnerabilities</li>
<li><strong>Simpler builds</strong>: Minimal dependency chain reduces compilation issues</li>
<li><strong>Smaller binaries</strong>: No transitive dependencies bloating your final executable</li>
</ul>
<h3 id="4-tensor-design-without-generics"><a class="header" href="#4-tensor-design-without-generics">4. Tensor Design Without Generics</a></h3>
<p>Zyx's tensor implementation avoids pervasive generics, which offers several benefits:</p>
<ul>
<li><strong>No type parameter propagation</strong>: Unlike systems that require generic parameters throughout the codebase, Zyx's tensors have fixed types.</li>
<li><strong>Simpler API</strong>: Developers don't need to manage complex generic type signatures across operations.</li>
<li><strong>Easier integration</strong>: Tensors can be used in more contexts without requiring generic type alignment.</li>
</ul>
<p>This design choice has practical implications:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Zyx tensor operation
impl CustomModel {
    fn forward(&amp;self, x: &amp;Tensor) -&gt; Tensor {
        let x = self.layer1.forward(x).unwrap().relu();
        self.layer2.forward(&amp;x).unwrap()
    }
}

// Hypothetical generic-based approach
impl&lt;T: DType, B: Backend&gt; CustomModel&lt;T, B&gt; {
    fn forward&lt;S: Shape&gt;(&amp;self, x: &amp;Tensor&lt;S, T, B&gt;) -&gt; Tensor&lt;S, T, B&gt; {
        let x = self.layer1.forward(x).unwrap().relu();
        self.layer2.forward(&amp;x).unwrap()
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="practical-usage-scenarios"><a class="header" href="#practical-usage-scenarios">Practical Usage Scenarios</a></h2>
<h3 id="general-linear-algebra-library"><a class="header" href="#general-linear-algebra-library">General Linear Algebra Library</a></h3>
<p>Zyx's design allows it to function as a general-purpose linear algebra library:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use zyx::{Tensor, DType};

// Basic tensor operations
let a = Tensor::from([1.0, 2.0, 3.0]);
let b = Tensor::from([4.0, 5.0, 6.0]);
let c = a + b;  // Element-wise addition
let d = c * 2.0;  // Scalar multiplication
<span class="boring">}</span></code></pre></pre>
<p>This example demonstrates how Zyx can be used for standard tensor operations without any framework-specific boilerplate.</p>
<h3 id="custom-training-loop-integration"><a class="header" href="#custom-training-loop-integration">Custom Training Loop Integration</a></h3>
<p>The library approach makes custom modules and training the default:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use zyx::{Tensor, DType, GradientTape};
use zyx_nn::{Linear, Module};
use zyx_optim::SGD;

#[derive(Module)]
struct CustomModel {
    layer1: Linear,
    layer2: Linear,
    learning_rate: f32,
}

impl CustomModel {
    fn forward(&amp;self, x: &amp;Tensor) -&gt; Tensor {
        let x = self.layer1.forward(x).unwrap().relu();
        self.layer2.forward(&amp;x).unwrap()
    }
}

fn train_step(model: &amp;mut CustomModel, optimizer: &amp;mut SGD, inputs: &amp;Tensor, targets: &amp;Tensor) -&gt; f32 {
    let tape = GradientTape::new();
    let outputs = model.forward(inputs);
    let loss = outputs.mse_loss(targets).unwrap();
    
    let gradients = tape.gradient(&amp;loss, model);
    optimizer.update(model, gradients);
    
    loss.item()
}
<span class="boring">}</span></code></pre></pre>
<p>This demonstrates how Zyx components can be integrated into a custom training workflow without framework constraints.</p>
<h3 id="memory-efficient-deployment"><a class="header" href="#memory-efficient-deployment">Memory-Efficient Deployment</a></h3>
<p>Zyx's minimal footprint makes it suitable for deployment scenarios:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In a deployment context
use zyx::{Tensor, DType};

fn process_input(input: &amp;[f32]) -&gt; Vec&lt;f32&gt; {
    let tensor = Tensor::from_slice(input, [1, input.len()]);
    let processed = tensor.sigmoid();  // Example activation
    processed.try_into().unwrap()
}
<span class="boring">}</span></code></pre></pre>
<p>This example shows how Zyx can be used in deployment without carrying framework-specific runtime overhead.</p>
<h2 id="comparative-analysis"><a class="header" href="#comparative-analysis">Comparative Analysis</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Traditional Frameworks</th><th>Zyx Library</th></tr></thead><tbody>
<tr><td>Graph definition</td><td>Static upfront</td><td>Dynamic, on-demand</td></tr>
<tr><td>Training loop</td><td>Predefined <code>fit()</code> method</td><td>Custom implementation</td></tr>
<tr><td>Memory usage</td><td>High (stores intermediates)</td><td>Optimized (tape-based)</td></tr>
<tr><td>Compilation size</td><td>Large binaries</td><td>Minimal footprint</td></tr>
<tr><td>Dependency chain</td><td>Complex</td><td>Minimal, focused</td></tr>
<tr><td>Generic type usage</td><td>Pervasive</td><td>Avoided</td></tr>
<tr><td>Debugging flexibility</td><td>Limited</td><td>Full control</td></tr>
<tr><td>Hardware utilization</td><td>Framework-bound</td><td>User-controlled</td></tr>
</tbody></table>
</div>
<h2 id="technical-implementation-details"><a class="header" href="#technical-implementation-details">Technical Implementation Details</a></h2>
<h3 id="lazy-execution-model"><a class="header" href="#lazy-execution-model">Lazy Execution Model</a></h3>
<p>Zyx's lazy execution model contributes to its lightweight nature:</p>
<ul>
<li>Tensors aren't realized until explicitly requested</li>
<li>Computation graphs are built only when needed</li>
<li>Memory allocation is optimized through deferred execution</li>
</ul>
<p>This approach enables efficient memory usage while maintaining flexibility:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tape = GradientTape::new();
let x = Tensor::randn([1024, 1024], DType::F32);
let y = x.relu();  // Not computed yet
let z = y * 2.0;    // Still just building the graph

// Computation happens here
Tensor::realize([&amp;z]).unwrap();
<span class="boring">}</span></code></pre></pre>
<h3 id="backend-agnosticism"><a class="header" href="#backend-agnosticism">Backend Agnosticism</a></h3>
<p>Zyx supports multiple backends without framework-level constraints:</p>
<ul>
<li>CUDA (PTX)</li>
<li>OpenCL</li>
<li>WGPU (WGSL)</li>
</ul>
<p>This allows users to choose hardware acceleration without being tied to framework-specific configuration. Developers don't need to be concerned where models will be deployed. Hardware is abstracted away as much as possible. But we are aware of leaky abstractions. Zyx works similarly to standard language compilers - code written in Rust can be deployed to many hardware targets, but knowledge of hardware quirks is still necessary when optimizing performance.</p>
<h3 id="error-handling-philosophy"><a class="header" href="#error-handling-philosophy">Error Handling Philosophy</a></h3>
<p>Zyx's error handling aligns with its library approach:</p>
<ul>
<li>Returns <code>Result</code> types for recoverable errors</li>
<li>Uses <code>panic!</code> only for unrecoverable hardware issues or internal bugs</li>
<li>Allows integration with both simple and complex error handling systems</li>
</ul>
<p>This approach provides flexibility:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple error handling
let tape = GradientTape::new();
let x = Tensor::randn([1024, 1024], DType::F32);
let y = x.relu();  // No Result type needed for non-fallible operations

// Complex error handling
fn safe_operation() -&gt; Result&lt;(), ZyxError&gt; {
    let tape = GradientTape::new();
    let x = Tensor::randn([1024, 1024], DType::F32)?; // Result will be returned on allocation failure
    let y = x.relu();
    let z = tape.gradient(&amp;y, &amp;[&amp;x]);
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h2>
<h3 id="for-researchers"><a class="header" href="#for-researchers">For Researchers</a></h3>
<p>The library model enables:</p>
<ul>
<li><strong>Rapid experimentation</strong>: Modify code without framework constraints</li>
<li><strong>Custom optimization strategies</strong>: Implement domain-specific optimizations</li>
<li><strong>Fine-grained control</strong>: Debug and inspect every computation step</li>
</ul>
<h3 id="for-engineers"><a class="header" href="#for-engineers">For Engineers</a></h3>
<p>When integrating ML into existing systems:</p>
<ul>
<li><strong>No architecture changes</strong>: Zyx adapts to your codebase, not vice versa</li>
<li><strong>Minimal binary impact</strong>: Add ML capabilities without bloating your executable</li>
<li><strong>Simplified dependency management</strong>: Avoid complex framework dependency trees</li>
</ul>
<h3 id="for-deployments"><a class="header" href="#for-deployments">For Deployments</a></h3>
<p>Zyx's design shines in production:</p>
<ul>
<li><strong>Small footprint</strong>: Ideal for edge devices with limited storage</li>
<li><strong>Flexible execution</strong>: Choose hardware acceleration based on deployment environment</li>
<li><strong>Simple error handling</strong>: Integrate with your existing error management system</li>
</ul>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Zyx's library-first design avoids framework-level constraints while offering:</p>
<ol>
<li><strong>Flexibility</strong> in code organization</li>
<li><strong>Minimal compilation footprint</strong> for efficient deployment</li>
<li><strong>Simplified tensor operations</strong> without generic type propagation</li>
<li><strong>Custom workflow support</strong> for both research and production environments</li>
<li><strong>Backend agnosticism</strong> with hardware flexibility</li>
</ol>
<p>This approach makes Zyx suitable for:</p>
<ul>
<li>Researchers needing custom training dynamics</li>
<li>Engineers integrating ML or linear algebra routines into existing systems</li>
<li>Developers working in resource-constrained environments</li>
</ul>
<p>The library model enables Zyx to be both powerful and lightweight, providing the best of both worlds for modern machine learning and linear algebra needs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="execution-model"><a class="header" href="#execution-model">Execution Model</a></h1>
<p>PyTorch executes most of the ops immediatelly. This straightforward, but it means that in order to be able to backpropagate, it needs to know which tensors must be stored in memory. Zyx uses lazy execution. It does not evaluate anything until user explicitly requests the data. This would not work for training/inference loops, so zyx uses caching mechanism that detects repetition of parts of graph and once any part of graph is repeated more than once, the whole graph get evaluated in order to remove no longer needed nodes (node is internal representation of unrealized tensor, takes only few bytes).</p>
<p>This is cool by itself, because it means that zyx is as dynamic as pytorch while allowing for optimizations only possible in static graphs, but it also allows zyx to be more dynamic than PyTorch, because there is no longer need to specify which tensors require gradient, as you can see in <a href="autograd.html">autograd</a> chapter.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<p>Zyx removes a number of PyTorch errors. Zyx tensors are immutable, so there is no:</p>
<ul>
<li>RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: ... , which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!</li>
</ul>
<p>Zyx technically allows mutability of tensors using set method, setting values of tensor A to tensor B, but tensors are just pointers, so this means merely that tensor B will now point to values previously pointed to be tensor A and tensor A will not exist anymore.</p>
<p>Another error that cannot occur:</p>
<ul>
<li>RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.</li>
</ul>
<p>Zyx does not store intermediate tensors, so they cannot be freed :)</p>
<h1 id="visualization"><a class="header" href="#visualization">Visualization</a></h1>
<p>One aspect of debugging which is often overlooked is visual representation of graph. Programmers often like reading code more than looking at visualizatinos, but in particular if you are using complex modules defined somewhere outside of your code, it may be beneficial to be able to look at any part of the graph visually.</p>
<p>Zyx asks you to give it any number of tensors and then plots all relations between them into picture. Let x, y and z be tensors.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let dot_graph = Tensor::plot_graph([&amp;x, &amp;y, &amp;z]);
fs::write("graph.dot", dot_graph).unwrap();
<span class="boring">}</span></code></pre></pre>
<p>If you want to see just forward part of graph, you can do for example this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let dot_graph = Tensor::plot_graph(model.into_iter().chain([&amp;x, &amp;loss]));
<span class="boring">}</span></code></pre></pre>
<p>Where model is your model, x is your input and loss is your loss/error.</p>
<p>If you want to only look at the backward part of graph, that is also simple:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let dot_graph = Tensor::plot_graph(grads.chain([&amp;loss]));
<span class="boring">}</span></code></pre></pre>
<p>Zyx will order nodes automatically, so there is no difference in the order in which tensors are stored in the iterator.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="runtime"><a class="header" href="#runtime">Runtime</a></h1>
<p>This is explanation of how zyx works under the hood.
Struct runtime holds the global state of zyx.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Runtime {
    graph: Graph,
    compiled_graphs: BTreeMap&lt;Graph, CompiledGraph&gt;,
    opencl: Option&lt;OpenCLBackend&gt;,
    devices: Vec&lt;Device&gt;,
    memory_pools: Vec&lt;MemoryPool&gt;,
    .. // less important fields
}
<span class="boring">}</span></code></pre></pre>
<p>Runtime stores this information:</p>
<ol>
<li>the current graph of tensor ops as called by the user</li>
<li>cached compiled graphs</li>
<li>all backends</li>
<li>all devices, which contain executable programs</li>
<li>all memory pools, which contain memory buffers</li>
</ol>
<p>What runtime does:</p>
<ol>
<li>converts tensor ops into graph nodes</li>
<li>tensor backpropagation by adding more nodes to graph</li>
<li>stores tensors on devices</li>
<li>passes graph into scheduler for compilation and caches compiled graph</li>
<li>launches compiled graphs</li>
</ol>
<h2 id="backend-model"><a class="header" href="#backend-model">Backend model</a></h2>
<p>Each backend needs to provide six structs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct XBackend { .. }
struct XError { .. }
struct XMemoryPool { .. }
struct XBuffer { .. }
struct XDevice { .. }
struct XProgram { .. }
<span class="boring">}</span></code></pre></pre>
<p>XBackend is the global state of each backend.
XError is enum of possible errors.
XMemoryPool is representation of memory pool accessible by that backend.
XBuffer is buffer stored in XMemoryPool.
XDevice is compute device capable of executing XPrograms.</p>
<p>Each backend can allocate memory, deallocate memory, copy memory between devices and host,
compile programs from IRKernels, launch them using devices and release resources that are not in use anymore.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
